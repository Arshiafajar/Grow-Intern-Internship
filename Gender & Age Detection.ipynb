{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e9ea2a-9291-4427-ac79-a43b8e5d0db3",
   "metadata": {},
   "source": [
    "# Grown Intern Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97336cbc-1a79-4f04-b366-e370c349c9e5",
   "metadata": {},
   "source": [
    "## Project Title: Gender & Age Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c601d4-de29-4296-8014-2cb227238061",
   "metadata": {},
   "source": [
    "### Installing Libararies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a292b-0ba9-4888-a29a-5992d6d2e8b9",
   "metadata": {},
   "source": [
    "- First we have to isnatll cmake to further install packages for face detectiona nd age detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35b52410-fdb5-4b70-a096-30a576d980a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in c:\\users\\pmls\\anaconda3\\lib\\site-packages (3.30.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cmake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c779a204-b8cf-468f-86c3-4f423a9ac888",
   "metadata": {},
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade setuptools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01c06765-12ab-44ed-8827-b598958ea36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\pmls\\downloads\\dlib-19.24.99-cp312-cp312-win_amd64.whl\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.24.99\n"
     ]
    }
   ],
   "source": [
    "!pip install \"C:\\Users\\PMLS\\Downloads\\dlib-19.24.99-cp312-cp312-win_amd64.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc23a495-5ba6-4e8b-9b66-b09aa35d9464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dlib in c:\\users\\pmls\\anaconda3\\lib\\site-packages (19.24.99)\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290a1ea-b62e-4ee6-897f-715e5d916cb6",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16d962e6-b498-4763-b856-9ad8c3811a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # for computer vision task \n",
    "import dlib # contains machine learning algorithims like face detection\n",
    "import numpy as np\n",
    "import os # Library for interacting with the operating system, like handling file paths.\n",
    "\n",
    "faceproto=\"opencv_face_detector.pbtxt\" # models configuration fro face detection\n",
    "facemode1=\"opencv_face_detector_unit8.pb\" # Model weights file for face detection\n",
    "\n",
    "age_weights = \"age_net.caffemodel\" # weights to age detection model files\n",
    "age_config = \"age_deploy.prototxt\" #configuration file for age detection model\n",
    "age_Net = cv2.dnn.readNet(age_config, age_weights) #loading the iamge detection model\n",
    "\n",
    "gender_weights = \"gender_net.caffemodel\" # paths to gender detection model files\n",
    "gender_config = \"gender_deploy.prototxt\" #weights for model\n",
    "\n",
    "gender_Net = cv2.dnn.readNet(gender_config, gender_weights) #loading the model \n",
    " \n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)',  # age and gender labels and model mean values\n",
    "           '(25-32)', '(38-43)', '(48-53)','(54-60)','(60-80)','(80-100)']\n",
    "genderList = ['Male', 'Female']\n",
    "model_mean = (78.4263377603, 87.7689143744, 114.895847746) #mean values for image processing\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector() # model for face detection\n",
    "                                             # directory containing images ( in my device)\n",
    "image_dir = r\"C:\\Users\\PMLS\\Desktop\\pics\"  # adjust this path if necessary\n",
    "\n",
    "# loop through all images in the directory, to detect them one by one\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.lower().endswith((\".jpeg\", \".jpg\", \".png\")):\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        \n",
    "        img = cv2.imread(img_path) # loading the image\n",
    "        frame = img.copy()\n",
    "\n",
    "        img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # converting to grayscale\n",
    "        \n",
    "        faces = face_detector(img_gray) # detecting faces\n",
    "        \n",
    "        if not faces:  # if no faces are detected\n",
    "            mssg = 'No face detected'\n",
    "            cv2.putText(img, f'{mssg}', (40, 40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (200), 2)\n",
    "            cv2.imshow('Age and Gender detected', img)\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            Boxes = []  # to store the face coordinates\n",
    "            mssg = 'Face Detected'  # to display on image\n",
    "            \n",
    "            # Bounding face\n",
    "            for face in faces:\n",
    "                x = face.left()  # extracting the face coordinates\n",
    "                y = face.top()\n",
    "                x2 = face.right()\n",
    "                y2 = face.bottom()\n",
    "\n",
    "                # rescaling those coordinates for our image\n",
    "                box = [x, y, x2, y2]\n",
    "                Boxes.append(box)\n",
    "                cv2.rectangle(frame, (x, y), (x2, y2),\n",
    "                              (0, 200, 200), 2)  #storing  these coordinates in a list and draw a rectangle around the face on the image.\n",
    "\n",
    "            for box in Boxes:\n",
    "                face = frame[box[1]:box[3], box[0]:box[2]]  #oordinates of the bounding box around the detected face.\n",
    "\n",
    "                blob = cv2.dnn.blobFromImage( # this function converts the image into a format suitable for neural network input\n",
    "                    face, 1.0, (227, 227), model_mean, swapRB=False)\n",
    "\n",
    "                age_Net.setInput(blob)  #  sets the preprocessed face blob as the input for the age detection neural network (age_Net).\n",
    "                age_preds = age_Net.forward() # runs a forward pass through the neural network to get the age prediction.\n",
    "                age = ageList[age_preds[0].argmax()] #inds the index of the highest probability in the predictions, indicating the most likely age group.\n",
    "\n",
    "                gender_Net.setInput(blob)  # gender prediction\n",
    "                gender_preds = gender_Net.forward()\n",
    "                gender = genderList[gender_preds[0].argmax()]\n",
    "\n",
    "                cv2.putText(frame, f'{mssg}: {age}, {gender}', (box[0],\n",
    "                                                                box[1] - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, # represeny the  font size, font style , color, and text size showing above image \n",
    "                             (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow(\"Detecting Age and Gender\", frame) #displays the image with the age and gender predictions.\n",
    "            cv2.waitKey(0) # allows you the watch the image as long as you want \n",
    "\n",
    "cv2.destroyAllWindows() # closes open cv after the directory has  looped over all images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9346a0e4-8fd0-4a5b-9a91-a9745bb52a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c855d-f9bb-4af9-ad58-dfa80fcbf983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8806038-e5af-42c9-a971-aace6e58abc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
